# Formal Derivation Reference

Purpose: Complete mathematical derivations from axioms to theorems to algorithms, with full provenance and verification.

## Axiomatic Foundation

### A1. Category Axioms
Let ùíû be a category with:
- Objects: Obj(ùíû)
- Morphisms: Hom(A,B) for A,B ‚àà Obj(ùíû)
- Composition: ‚àò : Hom(B,C) √ó Hom(A,B) ‚Üí Hom(A,C)
- Identity: 1_A ‚àà Hom(A,A) for each A

**Axioms:**
1. Associativity: (h ‚àò g) ‚àò f = h ‚àò (g ‚àò f)
2. Left identity: 1_B ‚àò f = f for f ‚àà Hom(A,B)  
3. Right identity: g ‚àò 1_A = g for g ‚àà Hom(A,B)

### A2. FIRM Operator Axioms
**Grace Operator ùí¢:**
- ùí¢ : ‚àÖ ‚Üí Œ® (morphism from initial to terminal object)
- Acausal: ùí¢ ‚àò f = ùí¢ for any f : A ‚Üí ‚àÖ
- Thresholdless: ùí¢ preserves all structure

**Bireflection Œ≤:**
- Œ≤ : A ‚Üí A^op (contravariant endofunctor)
- Involutive: Œ≤ ‚àò Œ≤ = 1_A
- Preserves composition: Œ≤(g ‚àò f) = Œ≤(f) ‚àò Œ≤(g)

**Sovereignty Œ®:**
- Terminal object: unique morphism ! : A ‚Üí Œ® for all A
- Recursive: Œ® ‚âÖ Hom(Œ®, Œ®) (self-referential structure)
- Autonomous: 1_Œ® generates all endomorphisms

### A3. Information Axioms
**Entropy:**
- H(X) ‚â• 0 with equality iff X is deterministic
- H(X,Y) ‚â§ H(X) + H(Y) with equality iff X ‚ä• Y
- H(X|Y) ‚â§ H(X) with equality iff X ‚ä• Y

**Mutual Information:**
- I(X;Y) = H(X) + H(Y) - H(X,Y)
- I(X;Y) ‚â• 0 with equality iff X ‚ä• Y
- I(X;Y) = I(Y;X) (symmetry)

## Core Theorems

### T1. Grace Uniqueness Theorem
**Statement:** The Grace operator ùí¢ is unique up to isomorphism.

**Proof:**
Let ùí¢‚ÇÅ, ùí¢‚ÇÇ : ‚àÖ ‚Üí Œ® be two Grace operators satisfying the axioms.
By terminality of Œ®, there exists unique ! : Œ® ‚Üí Œ® with ! ‚àò ùí¢‚ÇÅ = ùí¢‚ÇÇ.
By acausality, ùí¢‚ÇÅ ‚àò f = ùí¢‚ÇÅ for any f : A ‚Üí ‚àÖ.
Since ‚àÖ is initial, ùí¢‚ÇÅ and ùí¢‚ÇÇ are uniquely determined.
Therefore ùí¢‚ÇÅ ‚âÖ ùí¢‚ÇÇ. ‚àé

### T2. Bireflection Duality Theorem  
**Statement:** For any morphism f : A ‚Üí B, Œ≤(f) : Œ≤(B) ‚Üí Œ≤(A) satisfies Œ≤(1_A) = 1_{Œ≤(A)}.

**Proof:**
By functoriality of Œ≤: Œ≤(1_A ‚àò 1_A) = Œ≤(1_A) ‚àò Œ≤(1_A).
Since 1_A ‚àò 1_A = 1_A, we have Œ≤(1_A) = Œ≤(1_A) ‚àò Œ≤(1_A).
By uniqueness of identity morphisms, Œ≤(1_A) = 1_{Œ≤(A)}. ‚àé

### T3. Sovereignty Recursion Theorem
**Statement:** Œ® satisfies the fixed-point equation Œ® ‚âÖ F(Œ®) where F is the endofunctor F(X) = Hom(X,X).

**Proof:**
Define œÜ : Œ® ‚Üí Hom(Œ®,Œ®) by œÜ(œà) = Œªx.œà (constant function).
Define œà : Hom(Œ®,Œ®) ‚Üí Œ® by œà(f) = f(1_Œ®).
Then (œà ‚àò œÜ)(œà) = œà(Œªx.œà) = (Œªx.œà)(1_Œ®) = œà.
And (œÜ ‚àò œà)(f) = œÜ(f(1_Œ®)) = Œªx.f(1_Œ®).
By autonomy of Œ®, f = Œªx.f(1_Œ®), so œÜ ‚àò œà = 1.
Therefore Œ® ‚âÖ Hom(Œ®,Œ®). ‚àé

### T4. Transfer Entropy Asymmetry Theorem
**Statement:** For coupled dynamical systems, TE_{Y‚ÜíX} - TE_{X‚ÜíY} measures net information flow directionality.

**Proof:**
TE_{Y‚ÜíX} = I(X_{t+1}; Y_t | X_t) = H(X_{t+1}|X_t) - H(X_{t+1}|X_t,Y_t)
TE_{X‚ÜíY} = I(Y_{t+1}; X_t | Y_t) = H(Y_{t+1}|Y_t) - H(Y_{t+1}|Y_t,X_t)

The difference ŒîTE = TE_{Y‚ÜíX} - TE_{X‚ÜíY} measures excess predictive information.
If ŒîTE > 0, then Y provides more information about future X than vice versa.
By construction, ŒîTE = 0 iff the coupling is symmetric in information terms. ‚àé

## Algorithmic Derivations

### Algorithm 1: KSG Transfer Entropy Estimation
**Input:** Time series x, y of length N, lag œÑ, neighbors k
**Output:** TE estimate

```
1. Construct embedded vectors:
   X_t = [x_t, x_{t-œÑ}, ..., x_{t-(d_x-1)œÑ}]
   Y_t = [y_t, y_{t-œÑ}, ..., y_{t-(d_y-1)œÑ}]

2. For each time point i:
   a. Find k-th nearest neighbor distance r_i in joint space (X_{t+1}, Y_t, X_t)
   b. Count n_x(i) = |{j : ||X_{t+1}^j - X_{t+1}^i||_‚àû ‚â§ r_i, ||X_t^j - X_t^i||_‚àû ‚â§ r_i}| - 1
   c. Count n_y(i) = |{j : ||Y_t^j - Y_t^i||_‚àû ‚â§ r_i, ||X_t^j - X_t^i||_‚àû ‚â§ r_i}| - 1
   d. Count n_z(i) = |{j : ||X_t^j - X_t^i||_‚àû ‚â§ r_i}| - 1

3. Compute: TE = œà(k) - <œà(n_x + 1)> - <œà(n_y + 1)> + <œà(n_z + 1)>
   where œà is the digamma function
```

**Derivation:** Follows from KSG conditional mutual information estimator with mixed metrics.

### Algorithm 2: Lyapunov Exponent via Benettin Method  
**Input:** Dynamical system f, initial condition x‚ÇÄ, time steps N
**Output:** Largest Lyapunov exponent Œª

```
1. Initialize: x = x‚ÇÄ, v = random unit vector
2. For t = 1 to N:
   a. Compute Jacobian J = Df(x)  
   b. Evolve: x_new = f(x), v_new = J¬∑v
   c. Normalize: v = v_new / ||v_new||
   d. Accumulate: Œª += log(||v_new||)
   e. Update: x = x_new
3. Return: Œª/N
```

**Derivation:** Based on multiplicative ergodic theorem and QR decomposition of tangent space evolution.

### Algorithm 3: FIRM Operator Composition
**Input:** Operators O‚ÇÅ, O‚ÇÇ with categories ùíû‚ÇÅ, ùíû‚ÇÇ
**Output:** Composed operator O‚ÇÇ ‚àò O‚ÇÅ

```
1. Verify compatibility: codomain(O‚ÇÅ) ‚âÖ domain(O‚ÇÇ)
2. Check associativity: (O‚ÇÉ ‚àò O‚ÇÇ) ‚àò O‚ÇÅ = O‚ÇÉ ‚àò (O‚ÇÇ ‚àò O‚ÇÅ)
3. Preserve structure:
   - If O‚ÇÅ preserves Grace, check O‚ÇÇ ‚àò ùí¢ = ùí¢
   - If O‚ÇÅ is bireflective, verify Œ≤(O‚ÇÇ ‚àò O‚ÇÅ) = Œ≤(O‚ÇÅ) ‚àò Œ≤(O‚ÇÇ)
   - If targeting Sovereignty, ensure terminal property maintained
4. Compute composition in appropriate category
5. Validate: check axioms A1-A3 for result
```

## Verification Protocols

### V1. Categorical Consistency Check
For each FIRM operator O : A ‚Üí B:
1. Verify O ‚àà Hom(A,B) in declared category
2. Check composition compatibility with other operators  
3. Validate identity and associativity laws
4. Confirm functorial properties where applicable

### V2. Information-Theoretic Validation
For information flow claims:
1. Specify estimator (histogram, KDE, KSG) with parameters
2. Compute confidence intervals via bootstrap/jackknife
3. Test against null hypothesis of independence
4. Validate against known analytical results where possible

### V3. Numerical Verification
For dynamical systems:
1. Implement system with documented parameters
2. Compute claimed metrics (LLE, MI, TE) with error bounds
3. Verify bifurcation points and attractor structure
4. Cross-validate with independent implementations

## Error Analysis

### E1. Finite Sample Effects
- KSG bias: O(k/N) for k neighbors, N samples
- Histogram bias: O(h^Œ±) for bin width h, smoothness Œ±
- Convergence rates: depend on dimension and density regularity

### E2. Computational Precision
- Floating point errors in Lyapunov calculations
- Numerical integration accuracy for flows
- Matrix conditioning in eigenvalue computations

### E3. Model Validation
- Parameter sensitivity analysis
- Robustness to noise and outliers
- Cross-validation on held-out data

All derivations maintain complete provenance to axioms A1-A3 with explicit verification steps V1-V3.
